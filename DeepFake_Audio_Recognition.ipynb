{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-u-iHl6Qnys"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (your existing code)\n",
        "# Epoch 100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/Kaggle Train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Kaggle Validation'\n",
        "nb_train_samples = 74\n",
        "nb_validation_samples = 38\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "model.save_weights('first_try.h5')\n",
        "\n",
        "def test_model(model, test_data_dir, batch_size):\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=len(test_generator))\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy * 100}%\")\n",
        "\n",
        "    # Predict classes for the test data\n",
        "    y_true = test_generator.classes\n",
        "    y_pred = model.predict_generator(test_generator, steps=len(test_generator))\n",
        "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "\n",
        "    # Calculate and print precision, recall, and F1-score\n",
        "    report = classification_report(y_true, y_pred, target_names=['class 0', 'class 1'])\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Define the directory containing your test data\n",
        "test_data_dir = '/content/drive/MyDrive/Kaggle Test'\n",
        "\n",
        "# Call the test_model function to evaluate your model on the test data and calculate metrics\n",
        "test_model(model, test_data_dir, batch_size)\n",
        "\n",
        "# After training, you can use the model to predict whether an image is real or deepfake\n",
        "def predict_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    #print(img)\n",
        "    prediction = model.predict(img)\n",
        "    print(prediction)\n",
        "    return prediction[0][0]\n",
        "\n",
        "# Example usage:\n",
        "image_path_to_predict = '/content/drive/MyDrive/Real Images Dir/Images/LJ049-0079.png'\n",
        "prediction = predict_image(image_path_to_predict)\n",
        "if prediction >= 0.5000:\n",
        "    print(\"Real Image\")\n",
        "    print(\"There for it's an audio image of real audio.\")\n",
        "else:\n",
        "    print(\"Deepfake Image\")\n",
        "    print(\"There for it's an audio image of deep fake audio.\")\n",
        "# Create lists to store training and validation accuracy\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# Append accuracy values to the lists\n",
        "train_acc_history.extend(history.history['accuracy'])\n",
        "val_acc_history.extend(history.history['val_accuracy'])\n",
        "\n",
        "# Plotting the accuracy graph\n",
        "plt.plot(range(1, epochs + 1), train_acc_history, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs + 1), val_acc_history, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}